{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bXMwEwhrgpeK",
        "sQ5pyg8chMEp",
        "ZoOu_i6uh-gP",
        "7cRdII7MiONf"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 網路爬蟲"
      ],
      "metadata": {
        "id": "cbc4SjwfeYSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 載入selenium環境參數準備爬蟲"
      ],
      "metadata": {
        "id": "Q_oHCHvRdsCM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1WFQtHsV0e3",
        "outputId": "08f31982-defc-4b8b-9082-9fa3a7b216f4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-11 21:13:13--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/135.0.7049.84/linux64/chrome-linux64.zip\n",
            "Resolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\n",
            "Connecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/chrome-for-testing-public/135.0.7049.84/linux64/chrome-linux64.zip [following]\n",
            "--2025-04-11 21:13:13--  https://storage.googleapis.com/chrome-for-testing-public/135.0.7049.84/linux64/chrome-linux64.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.218.207, 142.251.31.207, 142.251.18.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.218.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169532832 (162M) [application/zip]\n",
            "Saving to: ‘chrome-linux64.zip’\n",
            "\n",
            "chrome-linux64.zip  100%[===================>] 161.68M  40.8MB/s    in 4.6s    \n",
            "\n",
            "2025-04-11 21:13:18 (35.2 MB/s) - ‘chrome-linux64.zip’ saved [169532832/169532832]\n",
            "\n",
            "--2025-04-11 21:13:24--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/135.0.7049.84/linux64/chromedriver-linux64.zip\n",
            "Resolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\n",
            "Connecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/chrome-for-testing-public/135.0.7049.84/linux64/chromedriver-linux64.zip [following]\n",
            "--2025-04-11 21:13:24--  https://storage.googleapis.com/chrome-for-testing-public/135.0.7049.84/linux64/chromedriver-linux64.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.218.207, 142.251.31.207, 142.251.18.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.218.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9578630 (9.1M) [application/zip]\n",
            "Saving to: ‘chromedriver.zip’\n",
            "\n",
            "chromedriver.zip    100%[===================>]   9.13M  10.4MB/s    in 0.9s    \n",
            "\n",
            "2025-04-11 21:13:25 (10.4 MB/s) - ‘chromedriver.zip’ saved [9578630/9578630]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/135.0.7049.84/linux64/chrome-linux64.zip -O chrome-linux64.zip\n",
        "!unzip -q chrome-linux64.zip\n",
        "!mv chrome-linux64 /opt/chrome\n",
        "\n",
        "import os\n",
        "os.environ['PATH'] += os.pathsep + \"/opt/chrome\"\n",
        "\n",
        "!wget https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/135.0.7049.84/linux64/chromedriver-linux64.zip -O chromedriver.zip\n",
        "!unzip -q chromedriver.zip\n",
        "!mv chromedriver-linux64/chromedriver /usr/bin/chromedriver\n",
        "!chmod +x /usr/bin/chromedriver\n",
        "\n",
        "!pip install selenium > /dev/null\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "import time\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
        "\n",
        "driver = webdriver.Chrome(service=Service(\"/usr/bin/chromedriver\"), options=chrome_options)"
      ],
      "metadata": {
        "id": "FS5-Ur_bXWZ4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 開始爬蟲，目標為bangumi上的動畫評論，記錄評論內容和分數"
      ],
      "metadata": {
        "id": "aAGl28jLeUcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://bangumi.tv/subject/454684\"+\"/comments\"\n",
        "driver.get(url)\n",
        "time.sleep(3)\n",
        "\n",
        "rating = []\n",
        "nextpage_times = 0\n",
        "maxpage = float(\"inf\")\n",
        "while nextpage_times < maxpage:\n",
        "  IDs = driver.find_elements(By.CLASS_NAME, \"text\")\n",
        "  for ID in IDs:\n",
        "    try:\n",
        "      Comment = ID.find_element(By.CLASS_NAME, \"comment\")\n",
        "      Score = ID.find_element(By.CLASS_NAME, \"starstop-s\")\n",
        "      rating.append({\n",
        "              \"comment\": Comment.text,\n",
        "              \"score\": Score.find_element(By.XPATH, \".//*\").get_attribute(\"class\").replace(\"starlight stars\",\"\")\n",
        "              })\n",
        "    except:\n",
        "      continue\n",
        "  print(f\"第 {nextpage_times+1}頁，評論總數：{len(rating)}\")\n",
        "\n",
        "  try:\n",
        "      next_link = driver.find_element(By.LINK_TEXT, \"››\")\n",
        "      next_link.click()\n",
        "      nextpage_times += 1\n",
        "      time.sleep(2)\n",
        "  except NoSuchElementException:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "liMxneoNJ8aN",
        "outputId": "af5f9ce4-e56f-4ea7-efac-158f05a3db5f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第 1頁，評論總數：18\n",
            "第 2頁，評論總數：37\n",
            "第 3頁，評論總數：57\n",
            "第 4頁，評論總數：77\n",
            "第 5頁，評論總數：97\n",
            "第 6頁，評論總數：114\n",
            "第 7頁，評論總數：132\n",
            "第 8頁，評論總數：149\n",
            "第 9頁，評論總數：169\n",
            "第 10頁，評論總數：189\n",
            "第 11頁，評論總數：209\n",
            "第 12頁，評論總數：226\n",
            "第 13頁，評論總數：243\n",
            "第 14頁，評論總數：262\n",
            "第 15頁，評論總數：280\n",
            "第 16頁，評論總數：298\n",
            "第 17頁，評論總數：315\n",
            "第 18頁，評論總數：332\n",
            "第 19頁，評論總數：349\n",
            "第 20頁，評論總數：368\n",
            "第 21頁，評論總數：387\n",
            "第 22頁，評論總數：407\n",
            "第 23頁，評論總數：424\n",
            "第 24頁，評論總數：444\n",
            "第 25頁，評論總數：462\n",
            "第 26頁，評論總數：481\n",
            "第 27頁，評論總數：501\n",
            "第 28頁，評論總數：520\n",
            "第 29頁，評論總數：540\n",
            "第 30頁，評論總數：560\n",
            "第 31頁，評論總數：579\n",
            "第 32頁，評論總數：598\n",
            "第 33頁，評論總數：618\n",
            "第 34頁，評論總數：638\n",
            "第 35頁，評論總數：655\n",
            "第 36頁，評論總數：674\n",
            "第 37頁，評論總數：693\n",
            "第 38頁，評論總數：713\n",
            "第 39頁，評論總數：733\n",
            "第 40頁，評論總數：751\n",
            "第 41頁，評論總數：768\n",
            "第 42頁，評論總數：783\n",
            "第 43頁，評論總數：803\n",
            "第 44頁，評論總數：822\n",
            "第 45頁，評論總數：839\n",
            "第 46頁，評論總數：859\n",
            "第 47頁，評論總數：877\n",
            "第 48頁，評論總數：894\n",
            "第 49頁，評論總數：914\n",
            "第 50頁，評論總數：931\n",
            "第 51頁，評論總數：950\n",
            "第 52頁，評論總數：970\n",
            "第 53頁，評論總數：987\n",
            "第 54頁，評論總數：1007\n",
            "第 55頁，評論總數：1026\n",
            "第 56頁，評論總數：1045\n",
            "第 57頁，評論總數：1064\n",
            "第 58頁，評論總數：1084\n",
            "第 59頁，評論總數：1104\n",
            "第 60頁，評論總數：1123\n",
            "第 61頁，評論總數：1143\n",
            "第 62頁，評論總數：1162\n",
            "第 63頁，評論總數：1182\n",
            "第 64頁，評論總數：1200\n",
            "第 65頁，評論總數：1219\n",
            "第 66頁，評論總數：1239\n",
            "第 67頁，評論總數：1259\n",
            "第 68頁，評論總數：1279\n",
            "第 69頁，評論總數：1299\n",
            "第 70頁，評論總數：1317\n",
            "第 71頁，評論總數：1337\n",
            "第 72頁，評論總數：1354\n",
            "第 73頁，評論總數：1373\n",
            "第 74頁，評論總數：1392\n",
            "第 75頁，評論總數：1412\n",
            "第 76頁，評論總數：1430\n",
            "第 77頁，評論總數：1449\n",
            "第 78頁，評論總數：1468\n",
            "第 79頁，評論總數：1488\n",
            "第 80頁，評論總數：1505\n",
            "第 81頁，評論總數：1525\n",
            "第 82頁，評論總數：1544\n",
            "第 83頁，評論總數：1564\n",
            "第 84頁，評論總數：1584\n",
            "第 85頁，評論總數：1604\n",
            "第 86頁，評論總數：1623\n",
            "第 87頁，評論總數：1643\n",
            "第 88頁，評論總數：1663\n",
            "第 89頁，評論總數：1682\n",
            "第 90頁，評論總數：1701\n",
            "第 91頁，評論總數：1720\n",
            "第 92頁，評論總數：1739\n",
            "第 93頁，評論總數：1759\n",
            "第 94頁，評論總數：1779\n",
            "第 95頁，評論總數：1799\n",
            "第 96頁，評論總數：1819\n",
            "第 97頁，評論總數：1838\n",
            "第 98頁，評論總數：1857\n",
            "第 99頁，評論總數：1876\n",
            "第 100頁，評論總數：1895\n",
            "第 101頁，評論總數：1914\n",
            "第 102頁，評論總數：1934\n",
            "第 103頁，評論總數：1954\n",
            "第 104頁，評論總數：1973\n",
            "第 105頁，評論總數：1991\n",
            "第 106頁，評論總數：2011\n",
            "第 107頁，評論總數：2030\n",
            "第 108頁，評論總數：2050\n",
            "第 109頁，評論總數：2070\n",
            "第 110頁，評論總數：2090\n",
            "第 111頁，評論總數：2108\n",
            "第 112頁，評論總數：2126\n",
            "第 113頁，評論總數：2143\n",
            "第 114頁，評論總數：2163\n",
            "第 115頁，評論總數：2183\n",
            "第 116頁，評論總數：2203\n",
            "第 117頁，評論總數：2220\n",
            "第 118頁，評論總數：2240\n",
            "第 119頁，評論總數：2259\n",
            "第 120頁，評論總數：2279\n",
            "第 121頁，評論總數：2299\n",
            "第 122頁，評論總數：2318\n",
            "第 123頁，評論總數：2338\n",
            "第 124頁，評論總數：2357\n",
            "第 125頁，評論總數：2377\n",
            "第 126頁，評論總數：2397\n",
            "第 127頁，評論總數：2413\n",
            "第 128頁，評論總數：2433\n",
            "第 129頁，評論總數：2452\n",
            "第 130頁，評論總數：2471\n",
            "第 131頁，評論總數：2491\n",
            "第 132頁，評論總數：2510\n",
            "第 133頁，評論總數：2530\n",
            "第 134頁，評論總數：2550\n",
            "第 135頁，評論總數：2569\n",
            "第 136頁，評論總數：2589\n",
            "第 137頁，評論總數：2609\n",
            "第 138頁，評論總數：2626\n",
            "第 139頁，評論總數：2646\n",
            "第 140頁，評論總數：2666\n",
            "第 141頁，評論總數：2684\n",
            "第 142頁，評論總數：2703\n",
            "第 143頁，評論總數：2721\n",
            "第 144頁，評論總數：2739\n",
            "第 145頁，評論總數：2758\n",
            "第 146頁，評論總數：2778\n",
            "第 147頁，評論總數：2798\n",
            "第 148頁，評論總數：2816\n",
            "第 149頁，評論總數：2835\n",
            "第 150頁，評論總數：2855\n",
            "第 151頁，評論總數：2873\n",
            "第 152頁，評論總數：2893\n",
            "第 153頁，評論總數：2913\n",
            "第 154頁，評論總數：2933\n",
            "第 155頁，評論總數：2951\n",
            "第 156頁，評論總數：2970\n",
            "第 157頁，評論總數：2989\n",
            "第 158頁，評論總數：3007\n",
            "第 159頁，評論總數：3027\n",
            "第 160頁，評論總數：3045\n",
            "第 161頁，評論總數：3064\n",
            "第 162頁，評論總數：3083\n",
            "第 163頁，評論總數：3103\n",
            "第 164頁，評論總數：3120\n",
            "第 165頁，評論總數：3138\n",
            "第 166頁，評論總數：3154\n",
            "第 167頁，評論總數：3172\n",
            "第 168頁，評論總數：3192\n",
            "第 169頁，評論總數：3211\n",
            "第 170頁，評論總數：3230\n",
            "第 171頁，評論總數：3249\n",
            "第 172頁，評論總數：3267\n",
            "第 173頁，評論總數：3287\n",
            "第 174頁，評論總數：3307\n",
            "第 175頁，評論總數：3326\n",
            "第 176頁，評論總數：3346\n",
            "第 177頁，評論總數：3365\n",
            "第 178頁，評論總數：3384\n",
            "第 179頁，評論總數：3402\n",
            "第 180頁，評論總數：3421\n",
            "第 181頁，評論總數：3441\n",
            "第 182頁，評論總數：3460\n",
            "第 183頁，評論總數：3480\n",
            "第 184頁，評論總數：3498\n",
            "第 185頁，評論總數：3517\n",
            "第 186頁，評論總數：3537\n",
            "第 187頁，評論總數：3556\n",
            "第 188頁，評論總數：3575\n",
            "第 189頁，評論總數：3594\n",
            "第 190頁，評論總數：3614\n",
            "第 191頁，評論總數：3632\n",
            "第 192頁，評論總數：3649\n",
            "第 193頁，評論總數：3667\n",
            "第 194頁，評論總數：3687\n",
            "第 195頁，評論總數：3706\n",
            "第 196頁，評論總數：3725\n",
            "第 197頁，評論總數：3745\n",
            "第 198頁，評論總數：3764\n",
            "第 199頁，評論總數：3784\n",
            "第 200頁，評論總數：3804\n",
            "第 201頁，評論總數：3823\n",
            "第 202頁，評論總數：3843\n",
            "第 203頁，評論總數：3861\n",
            "第 204頁，評論總數：3879\n",
            "第 205頁，評論總數：3899\n",
            "第 206頁，評論總數：3918\n",
            "第 207頁，評論總數：3937\n",
            "第 208頁，評論總數：3957\n",
            "第 209頁，評論總數：3976\n",
            "第 210頁，評論總數：3996\n",
            "第 211頁，評論總數：4016\n",
            "第 212頁，評論總數：4036\n",
            "第 213頁，評論總數：4053\n",
            "第 214頁，評論總數：4071\n",
            "第 215頁，評論總數：4088\n",
            "第 216頁，評論總數：4106\n",
            "第 217頁，評論總數：4123\n",
            "第 218頁，評論總數：4142\n",
            "第 219頁，評論總數：4160\n",
            "第 220頁，評論總數：4180\n",
            "第 221頁，評論總數：4199\n",
            "第 222頁，評論總數：4219\n",
            "第 223頁，評論總數：4238\n",
            "第 224頁，評論總數：4256\n",
            "第 225頁，評論總數：4275\n",
            "第 226頁，評論總數：4293\n",
            "第 227頁，評論總數：4311\n",
            "第 228頁，評論總數：4330\n",
            "第 229頁，評論總數：4349\n",
            "第 230頁，評論總數：4368\n",
            "第 231頁，評論總數：4388\n",
            "第 232頁，評論總數：4408\n",
            "第 233頁，評論總數：4425\n",
            "第 234頁，評論總數：4444\n",
            "第 235頁，評論總數：4463\n",
            "第 236頁，評論總數：4480\n",
            "第 237頁，評論總數：4498\n",
            "第 238頁，評論總數：4517\n",
            "第 239頁，評論總數：4536\n",
            "第 240頁，評論總數：4555\n",
            "第 241頁，評論總數：4573\n",
            "第 242頁，評論總數：4592\n",
            "第 243頁，評論總數：4611\n",
            "第 244頁，評論總數：4630\n",
            "第 245頁，評論總數：4649\n",
            "第 246頁，評論總數：4665\n",
            "第 247頁，評論總數：4682\n",
            "第 248頁，評論總數：4700\n",
            "第 249頁，評論總數：4716\n",
            "第 250頁，評論總數：4736\n",
            "第 251頁，評論總數：4755\n",
            "第 252頁，評論總數：4774\n",
            "第 253頁，評論總數：4793\n",
            "第 254頁，評論總數：4810\n",
            "第 255頁，評論總數：4829\n",
            "第 256頁，評論總數：4848\n",
            "第 257頁，評論總數：4868\n",
            "第 258頁，評論總數：4886\n",
            "第 259頁，評論總數：4905\n",
            "第 260頁，評論總數：4922\n",
            "第 261頁，評論總數：4940\n",
            "第 262頁，評論總數：4955\n",
            "第 263頁，評論總數：4972\n",
            "第 264頁，評論總數：4992\n",
            "第 265頁，評論總數：5012\n",
            "第 266頁，評論總數：5029\n",
            "第 267頁，評論總數：5049\n",
            "第 268頁，評論總數：5068\n",
            "第 269頁，評論總數：5087\n",
            "第 270頁，評論總數：5106\n",
            "第 271頁，評論總數：5124\n",
            "第 272頁，評論總數：5140\n",
            "第 273頁，評論總數：5160\n",
            "第 274頁，評論總數：5179\n",
            "第 275頁，評論總數：5198\n",
            "第 276頁，評論總數：5214\n",
            "第 277頁，評論總數：5233\n",
            "第 278頁，評論總數：5253\n",
            "第 279頁，評論總數：5270\n",
            "第 280頁，評論總數：5287\n",
            "第 281頁，評論總數：5306\n",
            "第 282頁，評論總數：5322\n",
            "第 283頁，評論總數：5342\n",
            "第 284頁，評論總數：5361\n",
            "第 285頁，評論總數：5379\n",
            "第 286頁，評論總數：5397\n",
            "第 287頁，評論總數：5416\n",
            "第 288頁，評論總數：5434\n",
            "第 289頁，評論總數：5453\n",
            "第 290頁，評論總數：5472\n",
            "第 291頁，評論總數：5490\n",
            "第 292頁，評論總數：5508\n",
            "第 293頁，評論總數：5527\n",
            "第 294頁，評論總數：5547\n",
            "第 295頁，評論總數：5566\n",
            "第 296頁，評論總數：5585\n",
            "第 297頁，評論總數：5604\n",
            "第 298頁，評論總數：5623\n",
            "第 299頁，評論總數：5641\n",
            "第 300頁，評論總數：5661\n",
            "第 301頁，評論總數：5678\n",
            "第 302頁，評論總數：5696\n",
            "第 303頁，評論總數：5716\n",
            "第 304頁，評論總數：5734\n",
            "第 305頁，評論總數：5752\n",
            "第 306頁，評論總數：5772\n",
            "第 307頁，評論總數：5790\n",
            "第 308頁，評論總數：5809\n",
            "第 309頁，評論總數：5825\n",
            "第 310頁，評論總數：5840\n",
            "第 311頁，評論總數：5857\n",
            "第 312頁，評論總數：5875\n",
            "第 313頁，評論總數：5894\n",
            "第 314頁，評論總數：5909\n",
            "第 315頁，評論總數：5926\n",
            "第 316頁，評論總數：5945\n",
            "第 317頁，評論總數：5961\n",
            "第 318頁，評論總數：5981\n",
            "第 319頁，評論總數：5994\n",
            "第 320頁，評論總數：6011\n",
            "第 321頁，評論總數：6029\n",
            "第 322頁，評論總數：6042\n",
            "第 323頁，評論總數：6059\n",
            "第 324頁，評論總數：6077\n",
            "第 325頁，評論總數：6096\n",
            "第 326頁，評論總數：6116\n",
            "第 327頁，評論總數：6130\n",
            "第 328頁，評論總數：6147\n",
            "第 329頁，評論總數：6166\n",
            "第 330頁，評論總數：6178\n",
            "第 331頁，評論總數：6197\n",
            "第 332頁，評論總數：6207\n",
            "第 333頁，評論總數：6215\n",
            "第 334頁，評論總數：6218\n",
            "第 335頁，評論總數：6220\n",
            "第 336頁，評論總數：6221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 畫出分數的分配比例圖"
      ],
      "metadata": {
        "id": "tCSPqKZfe5dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "labels = [int(item[\"score\"]) for item in rating]\n",
        "label_counts = Counter(labels)\n",
        "\n",
        "x = sorted(label_counts.keys())\n",
        "y = [label_counts[i] for i in x]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(x, y, color='skyblue')\n",
        "plt.xlabel(\"Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Label Distribution\")\n",
        "plt.xticks(x)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Ya50ly-LuaR6",
        "outputId": "a70ead47-ead2-4a1b-c490-8ec3906c7920"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 分割為train，validation和test三個檔案，並存為jsonl檔為後續fine tuning作準備"
      ],
      "metadata": {
        "id": "Vj1uBPrRfX5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "train_data, temp_data = train_test_split(rating, test_size=0.2, random_state=42)\n",
        "valid_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "def save_jsonl(data, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for item in data:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "save_jsonl(rating, \"rating.jsonl\")\n",
        "save_jsonl(train_data, \"train_data.jsonl\")\n",
        "save_jsonl(valid_data, \"valid_data.jsonl\")\n",
        "save_jsonl(test_data, \"test_data.jsonl\")"
      ],
      "metadata": {
        "id": "LH5kpewXmkvh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fine tuning model"
      ],
      "metadata": {
        "id": "XwTK30o7ffB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 下載hugging face的library作準備"
      ],
      "metadata": {
        "id": "eQ9gZ5D8fr_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q\n",
        "!pip install datasets\n",
        "import torch\n",
        "\n",
        "from datasets import Dataset\n"
      ],
      "metadata": {
        "id": "h3xVC-E1kfAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c2704cf0-24d6-4c0b-8afc-d57e699f0da2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 讀取爬蟲時存下的jsonl檔"
      ],
      "metadata": {
        "id": "7UwE7Pxpf7EM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_json(\"train_data.jsonl\")\n",
        "valid_dataset = Dataset.from_json(\"valid_data.jsonl\")\n",
        "test_dataset = Dataset.from_json(\"test_data.jsonl\")"
      ],
      "metadata": {
        "id": "xun-atU0lHVG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize，並將分數label簡化為三類以得到更好的training效果"
      ],
      "metadata": {
        "id": "7AlnAH81gMOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BertTokenizer, AutoModelForSequenceClassification, BertForSequenceClassification, DataCollatorWithPadding\n",
        "import math\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('uer/roberta-small-word-chinese-cluecorpussmall')\n",
        "\n",
        "def map_to_3class(score):\n",
        "    s = int(score)\n",
        "    if s <= 3:\n",
        "        return 0\n",
        "    elif s <= 7:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "def tokenize_function(dataset):\n",
        "    tokenized = tokenizer(dataset[\"comment\"], truncation=True)\n",
        "    tokenized[\"labels\"] = [map_to_3class(s) for s in dataset[\"score\"]]\n",
        "    return tokenized\n",
        "\n",
        "def preprocess_function(dataset):\n",
        "    PreprocessData = dataset.map(tokenize_function, batched=True)\n",
        "    PreprocessData = PreprocessData.remove_columns([\"comment\", \"score\"])\n",
        "    return PreprocessData\n",
        "\n",
        "tokenize_train_datasets = preprocess_function(train_dataset)\n",
        "tokenize_valid_datasets = preprocess_function(valid_dataset)\n",
        "tokenize_test_datasets = preprocess_function(test_dataset)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYlWdKjck6Rk",
        "outputId": "377b3385-3bcb-42e6-f1b3-d7ce1825f21b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 開始training"
      ],
      "metadata": {
        "id": "CHo0I50-glgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 設定模型參數"
      ],
      "metadata": {
        "id": "bXMwEwhrgpeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import trainer, get_scheduler, DataCollatorWithPadding\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"uer/roberta-small-word-chinese-cluecorpussmall\", num_labels=5)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "num_epochs = 100\n",
        "model_name = \"AnimeComment\"\n",
        "\n",
        "train_loader = DataLoader(tokenize_train_datasets, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
        "eval_loader = DataLoader(tokenize_valid_datasets, batch_size=batch_size, collate_fn=data_collator)\n",
        "\n",
        "# Optimizer & Scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.05)\n",
        "num_training_steps = len(train_loader) * num_epochs\n",
        "warmup_steps = num_training_steps * 0.1\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"cosine\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# compute metrics\n",
        "def compute_metrics(preds, labels):\n",
        "    preds = torch.argmax(preds, dim=-1).cpu().numpy()\n",
        "    labels = labels.cpu().numpy()\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': round(acc, 4),\n",
        "        'precision': round(precision, 4),\n",
        "        'recall': round(recall, 4),\n",
        "        'f1': round(f1, 4)\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "QWi15M0g3jwm",
        "outputId": "46e7c4f5-85a0-4438-e94e-ca16a000c3b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-macbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1626: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-4-a6fe9279d96b>:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcamelmaycry\u001b[0m (\u001b[33mcamelmaycry-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250411_154942-k3nz01bx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/camelmaycry-none/huggingface/runs/k3nz01bx' target=\"_blank\">AnimeComment</a></strong> to <a href='https://wandb.ai/camelmaycry-none/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/camelmaycry-none/huggingface' target=\"_blank\">https://wandb.ai/camelmaycry-none/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/camelmaycry-none/huggingface/runs/k3nz01bx' target=\"_blank\">https://wandb.ai/camelmaycry-none/huggingface/runs/k3nz01bx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [292/292 1:10:03, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.753400</td>\n",
              "      <td>0.624685</td>\n",
              "      <td>0.834483</td>\n",
              "      <td>0.696361</td>\n",
              "      <td>0.834483</td>\n",
              "      <td>0.759191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.678600</td>\n",
              "      <td>0.564072</td>\n",
              "      <td>0.834483</td>\n",
              "      <td>0.696361</td>\n",
              "      <td>0.834483</td>\n",
              "      <td>0.759191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=292, training_loss=0.8382787606487535, metrics={'train_runtime': 4246.6665, 'train_samples_per_second': 0.547, 'train_steps_per_second': 0.069, 'total_flos': 162044802574284.0, 'train_loss': 0.8382787606487535, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 開始training"
      ],
      "metadata": {
        "id": "sQ5pyg8chMEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data for picture drawing\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Early stopping parameter\n",
        "best_f1 = 0\n",
        "patience_counter = 0\n",
        "early_stopping_patience = 5\n",
        "\n",
        "# training epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # train\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        correct_preds += (preds == batch[\"labels\"]).sum().item()\n",
        "        total_preds += batch[\"labels\"].size(0)\n",
        "\n",
        "    epoch_train_loss = total_loss / len(train_loader)\n",
        "    epoch_train_accuracy = correct_preds / total_preds\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    train_accuracies.append(epoch_train_accuracy)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {epoch_train_loss:.4f}, Train Accuracy = {epoch_train_accuracy:.4f}\")\n",
        "\n",
        "    # evaluate\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    eval_loss = 0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(eval_loader, desc=\"Evaluating\"):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            eval_loss += outputs.loss.item()\n",
        "            preds = torch.argmax(outputs.logits, dim=-1)\n",
        "            correct_preds += (preds == batch[\"labels\"]).sum().item()\n",
        "            total_preds += batch[\"labels\"].size(0)\n",
        "            all_preds.append(outputs.logits)\n",
        "            all_labels.append(batch[\"labels\"])\n",
        "\n",
        "    epoch_eval_loss = eval_loss / len(eval_loader)\n",
        "    epoch_eval_accuracy = correct_preds / total_preds\n",
        "    val_losses.append(epoch_eval_loss)\n",
        "    val_accuracies.append(epoch_eval_accuracy)\n",
        "\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    metrics = compute_metrics(all_preds, all_labels)\n",
        "    print(f\"Validation Loss: {epoch_eval_loss:.4f}, Validation Accuracy: {epoch_eval_accuracy:.4f}, Metrics: {metrics}\")\n",
        "\n",
        "    final_epoch = epoch\n",
        "\n",
        "    # Early Stopping & Save\n",
        "    if metrics[\"f1\"] > best_f1:\n",
        "        best_f1 = metrics[\"f1\"]\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(\"Model saved.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LXKFZq_aJXCA",
        "outputId": "dbff182b-2bea-49ad-bfbf-77411d1fc87c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-macbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧪 Checking batch 0\n",
            "input_ids: shape=torch.Size([32, 118]), dtype=torch.int64, device=cpu\n",
            "token_type_ids: shape=torch.Size([32, 118]), dtype=torch.int64, device=cpu\n",
            "attention_mask: shape=torch.Size([32, 118]), dtype=torch.int64, device=cpu\n",
            "labels: shape=torch.Size([32]), dtype=torch.int64, device=cpu\n",
            "Labels: tensor([3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 3, 3, 3, 3, 3, 3, 3])\n",
            "Unique labels in batch: tensor([3, 4])\n",
            "✅ Batch 0 passed. Loss: 1.4046\n",
            "\n",
            "🧪 Checking batch 1\n",
            "input_ids: shape=torch.Size([32, 191]), dtype=torch.int64, device=cpu\n",
            "token_type_ids: shape=torch.Size([32, 191]), dtype=torch.int64, device=cpu\n",
            "attention_mask: shape=torch.Size([32, 191]), dtype=torch.int64, device=cpu\n",
            "labels: shape=torch.Size([32]), dtype=torch.int64, device=cpu\n",
            "Labels: tensor([3, 3, 3, 3, 4, 3, 3, 4, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 4, 3])\n",
            "Unique labels in batch: tensor([2, 3, 4])\n",
            "✅ Batch 1 passed. Loss: 1.4712\n",
            "\n",
            "🧪 Checking batch 2\n",
            "input_ids: shape=torch.Size([32, 111]), dtype=torch.int64, device=cpu\n",
            "token_type_ids: shape=torch.Size([32, 111]), dtype=torch.int64, device=cpu\n",
            "attention_mask: shape=torch.Size([32, 111]), dtype=torch.int64, device=cpu\n",
            "labels: shape=torch.Size([32]), dtype=torch.int64, device=cpu\n",
            "Labels: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 4, 2, 3, 3, 3,\n",
            "        3, 3, 3, 3, 4, 3, 3, 3])\n",
            "Unique labels in batch: tensor([2, 3, 4])\n",
            "✅ Batch 2 passed. Loss: 1.4645\n",
            "\n",
            "🧪 Checking batch 3\n",
            "input_ids: shape=torch.Size([32, 282]), dtype=torch.int64, device=cpu\n",
            "token_type_ids: shape=torch.Size([32, 282]), dtype=torch.int64, device=cpu\n",
            "attention_mask: shape=torch.Size([32, 282]), dtype=torch.int64, device=cpu\n",
            "labels: shape=torch.Size([32]), dtype=torch.int64, device=cpu\n",
            "Labels: tensor([3, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        2, 3, 3, 3, 3, 3, 3, 3])\n",
            "Unique labels in batch: tensor([2, 3, 4])\n",
            "✅ Batch 3 passed. Loss: 1.4414\n",
            "\n",
            "🧪 Checking batch 4\n",
            "input_ids: shape=torch.Size([17, 366]), dtype=torch.int64, device=cpu\n",
            "token_type_ids: shape=torch.Size([17, 366]), dtype=torch.int64, device=cpu\n",
            "attention_mask: shape=torch.Size([17, 366]), dtype=torch.int64, device=cpu\n",
            "labels: shape=torch.Size([17]), dtype=torch.int64, device=cpu\n",
            "Labels: tensor([3, 3, 3, 3, 3, 3, 2, 2, 4, 2, 3, 3, 3, 2, 3, 2, 3])\n",
            "Unique labels in batch: tensor([2, 3, 4])\n",
            "✅ Batch 4 passed. Loss: 1.4752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 畫出learning curve"
      ],
      "metadata": {
        "id": "ZoOu_i6uh-gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(1, final_epoch + 2), train_losses, 'b-', label=\"Train Loss\")\n",
        "plt.plot(range(1, final_epoch + 2), val_losses, 'b--', label=\"Val Loss\")\n",
        "plt.plot(range(1, final_epoch + 2), train_accuracies, 'r-', label=\"Train Accuracy\")\n",
        "plt.plot(range(1, final_epoch + 2), val_accuracies, 'r--', label=\"Val Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss / Accuracy\")\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "z5-wxHrL7R2c",
        "outputId": "97af5ff9-f065-4013-c27c-b228d7fe53bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcamelmaycry\u001b[0m (\u001b[33mcamelmaycry-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250411_153650-udxfi2v6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/camelmaycry-none/huggingface/runs/udxfi2v6' target=\"_blank\">AnimeComment</a></strong> to <a href='https://wandb.ai/camelmaycry-none/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/camelmaycry-none/huggingface' target=\"_blank\">https://wandb.ai/camelmaycry-none/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/camelmaycry-none/huggingface/runs/udxfi2v6' target=\"_blank\">https://wandb.ai/camelmaycry-none/huggingface/runs/udxfi2v6</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 儲存model參數"
      ],
      "metadata": {
        "id": "7cRdII7MiONf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(f\"{model_name}_best\")\n",
        "tokenizer.save_pretrained(f\"{model_name}_best\")"
      ],
      "metadata": {
        "id": "G9vaOPWappM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 開始testing"
      ],
      "metadata": {
        "id": "SWvvKrpbid6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_dataset, tokenizer, batch_size=32, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=data_collator\n",
        "    )\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")\n",
        "    print(f\"Test Precision: {precision:.4f}\")\n",
        "    print(f\"Test Recall: {recall:.4f}\")\n",
        "    print(f\"Test F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return all_preds, all_labels\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_preds, test_labels = test_model(model, tokenize_test_datasets, tokenizer, batch_size=32, device=device)"
      ],
      "metadata": {
        "id": "nJ3RR9uWiaj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inference"
      ],
      "metadata": {
        "id": "32CWLQVXi8tJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 設定inference功能"
      ],
      "metadata": {
        "id": "4gv_wuChjCaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_path = \"AnimeComment_best\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def inference_function(texts):\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    return predictions.cpu().numpy()"
      ],
      "metadata": {
        "id": "TG0zY6PZiydn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 實測inference"
      ],
      "metadata": {
        "id": "bvgax8jGjLjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"祥子與他的伙伴們的過家家，最後大團圓也拉不回分數\"\n",
        "prediction = inference_function(test_text)\n",
        "print(f\"Predicted label: {prediction}\")"
      ],
      "metadata": {
        "id": "Q5DZ5-78jJ0e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}